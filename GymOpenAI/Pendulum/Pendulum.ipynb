{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def gather_data(env):\n",
    "#     num_trials = 10000\n",
    "#     min_score = 50\n",
    "#     sim_steps = 500\n",
    "#     trainingX, trainingY = [], []\n",
    "\n",
    "#     scores = []\n",
    "#     for _ in range(num_trials):\n",
    "#         observation = env.reset()\n",
    "#         score = 0\n",
    "#         training_sampleX, training_sampleY = [], []\n",
    "#         for step in range(sim_steps):\n",
    "#             # action corresponds to the previous observation so record before step\n",
    "#             action = np.random.randint(0, 2)\n",
    "#             one_hot_action = np.zeros(2)\n",
    "#             one_hot_action[action] = 1\n",
    "#             training_sampleX.append(observation)\n",
    "#             training_sampleY.append(one_hot_action)\n",
    "\n",
    "#             observation, reward, done, _ = env.step(action)\n",
    "#             score += reward\n",
    "#             if done:\n",
    "#                 break\n",
    "#         if score > min_score:\n",
    "#             scores.append(score)\n",
    "#             trainingX += training_sampleX\n",
    "#             trainingY += training_sampleY\n",
    "\n",
    "#     trainingX, trainingY = np.array(trainingX), np.array(trainingY)\n",
    "#     print(\"Average: {}\".format(np.mean(scores)))\n",
    "#     print(\"Median: {}\".format(np.median(scores)))\n",
    "#     return trainingX, trainingY\n",
    "\n",
    "\n",
    "def gather_data(env):\n",
    "    num_trials = 10000\n",
    "    min_score = -800\n",
    "    sim_steps = 200\n",
    "    trainingX, trainingY = [], []\n",
    "    scores = []\n",
    "    for _ in range (num_trials):\n",
    "        observations = env.reset()\n",
    "        score = 0\n",
    "        training_sampleX, training_sampleY = [], []\n",
    "        for _ in range(sim_steps):\n",
    "            action = np.random.uniform(-2,2)\n",
    "            one_hot_action = np.zeros(1)\n",
    "            one_hot_action[0] = action\n",
    "            training_sampleX.append(observations)\n",
    "            training_sampleY.append(action)         \n",
    "            observations, reward, done, _ = env.step(one_hot_action)\n",
    "            if done:\n",
    "                break\n",
    "            score += reward\n",
    "        if score > min_score:\n",
    "            scores.append(score)\n",
    "            trainingX += training_sampleX\n",
    "            trainingY += training_sampleY\n",
    "    trainingX, trainingY = np.array(trainingX), np.array(trainingY)\n",
    "    return trainingX, trainingY\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingX, trainingY = gather_data(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingY.size/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(3,), activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(1, activation=\"relu\"))\n",
    "\n",
    "    model.compile(loss=\"mean_squared_logarithmic_error\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73000 samples\n",
      "Epoch 1/2\n",
      "73000/73000 [==============================] - 8s 114us/sample - loss: 0.1705 - accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "73000/73000 [==============================] - 7s 102us/sample - loss: 0.1527 - accuracy: 0.0000e+00\n",
      "-6.574621205398349\n",
      "-13.249217184927367\n",
      "-20.160266417773244\n",
      "-27.436783913866073\n",
      "-35.19476740785969\n",
      "-43.53161018037983\n",
      "-52.52099037202164\n",
      "-62.20893834760216\n",
      "-72.51606577378705\n",
      "-82.1441356695474\n",
      "-91.10758024359775\n",
      "-99.4460148546431\n",
      "-107.22380044915349\n",
      "-114.52804281466\n",
      "-121.46524815062544\n",
      "-128.15707470163494\n",
      "-134.73563010379644\n",
      "-141.33860156087374\n",
      "-148.10428632146275\n",
      "-155.16643786558615\n",
      "-162.64884185573362\n",
      "-170.65970184838264\n",
      "-179.2861903897063\n",
      "-188.58978368290062\n",
      "-198.60309823042417\n",
      "-208.6007472732467\n",
      "-217.92282325556056\n",
      "-226.59518322224028\n",
      "-234.6688622190293\n",
      "-242.21891762538075\n",
      "-249.3417714568931\n",
      "-256.15139412682873\n",
      "-262.77480029799796\n",
      "-269.34724790528304\n",
      "-276.00732650890217\n",
      "-282.8919184539313\n",
      "-290.13092624406465\n",
      "-297.84173675787906\n",
      "-306.12362036516754\n",
      "-315.0525508273966\n",
      "-324.6771381945184\n",
      "-335.01635319888817\n",
      "-344.70472099487716\n",
      "-353.726160675679\n",
      "-362.11803795330695\n",
      "-369.9425672706005\n",
      "-377.2849461095178\n",
      "-384.2501142878062\n",
      "-390.9585665664819\n",
      "-397.54167563729834\n",
      "-404.1368313669244\n",
      "-410.88248225414014\n",
      "-417.91300274244907\n",
      "-425.35329349936467\n",
      "-433.31317405203106\n",
      "-441.88189720631493\n",
      "-451.1233845017276\n",
      "-461.07290210077343\n",
      "-471.1311645522432\n",
      "-480.5127693879821\n",
      "-489.24132720142404\n",
      "-497.3656526289028\n",
      "-504.95874966719623\n",
      "-512.1152774281277\n",
      "-518.9478183588506\n",
      "-525.5824171201929\n",
      "-532.153795118292\n",
      "-538.8004469365331\n",
      "-545.6596169436274\n",
      "-552.8620510473409\n",
      "-560.5264804612846\n",
      "-568.7540110285845\n",
      "-577.6228793585738\n",
      "-587.184256838468\n",
      "-597.4597924871393\n",
      "-607.2085544489497\n",
      "-616.2882861802784\n",
      "-624.734101481483\n",
      "-632.6060533370862\n",
      "-639.9874048841493\n",
      "-646.9814959849463\n",
      "-653.7076205646229\n",
      "-660.2963777151689\n",
      "-666.8848206487351\n",
      "-673.6115084267698\n",
      "-680.6113935434324\n",
      "-688.010446921237\n",
      "-695.9200600839087\n",
      "-704.431527759658\n",
      "-713.6111900189713\n",
      "-723.4969521944803\n",
      "-733.6158182777402\n",
      "-743.057139118652\n",
      "-751.8422831366393\n",
      "-760.0178364947747\n",
      "-767.6547294516596\n",
      "-774.8458282497475\n",
      "-781.7022916609087\n",
      "-788.3491562013421\n",
      "-794.9205678148912\n",
      "-801.5548862962402\n",
      "-808.3896763985473\n",
      "-815.5564835162959\n",
      "-823.1753383289212\n",
      "-831.349140038956\n",
      "-840.1583542987864\n",
      "-849.6566940186101\n",
      "-859.8684842099732\n",
      "-869.6777190173483\n",
      "-878.8160217650624\n",
      "-887.3162531878482\n",
      "-895.2362909628941\n",
      "-902.657438703959\n",
      "-909.6814032535972\n",
      "-916.4262405590373\n",
      "-923.0217375208032\n",
      "-929.6045714539939\n",
      "-936.3133714599252\n",
      "-943.2836253804466\n",
      "-950.6423297371441\n",
      "-958.5024038380309\n",
      "-966.9571452565591\n",
      "-976.07528453385\n",
      "-985.8973541065347\n",
      "-996.0767970569453\n",
      "-1005.5780031635777\n",
      "-1014.4201039494551\n",
      "-1022.6474501834135\n",
      "-1030.3288790480656\n",
      "-1037.5554346549231\n",
      "-1044.4368167500504\n",
      "-1051.0970156843584\n",
      "-1057.6695630582622\n",
      "-1064.292644178872\n",
      "-1071.104102743199\n",
      "-1078.236239897518\n",
      "-1085.8103408873424\n",
      "-1093.9310557078863\n",
      "-1102.6810442647\n",
      "-1112.116539739504\n",
      "-1122.2645392308345\n",
      "-1132.1343080595568\n",
      "-1141.3314428035255\n",
      "-1149.886551075935\n",
      "-1157.8553225147657\n",
      "-1165.3170769215633\n",
      "-1172.3718555957525\n",
      "-1179.136439596163\n",
      "-1185.7397651099081\n",
      "-1192.3180943815864\n",
      "-1199.0100861861763\n",
      "-1205.9517212211792\n",
      "-1213.2709770643387\n",
      "-1221.0822563954594\n",
      "-1229.4808198645535\n",
      "-1238.5377592091065\n",
      "-1248.296220343348\n",
      "-1258.5361965265147\n",
      "-1268.097439312237\n",
      "-1276.9968495800779\n",
      "-1285.276536924871\n",
      "-1293.0032271539076\n",
      "-1300.2661137219113\n",
      "-1307.1734023852446\n",
      "-1313.8479994453266\n",
      "-1320.4227833301975\n",
      "-1327.03572526525\n",
      "-1333.8249066440414\n",
      "-1340.923340820617\n",
      "-1348.453522704329\n",
      "-1356.5218101079038\n",
      "-1365.2130214624494\n",
      "-1374.5858875640865\n",
      "-1384.6700720816052\n",
      "-1394.6004186920263\n",
      "-1403.8566284269587\n",
      "-1412.467056805144\n",
      "-1420.4851938200625\n",
      "-1427.9883520892179\n",
      "-1435.0748754180086\n",
      "-1441.8602333204963\n",
      "-1448.4724728255896\n",
      "-1455.0474019979479\n",
      "-1461.7236690682219\n",
      "-1468.637705308276\n",
      "-1475.9184249392506\n",
      "-1483.681669436554\n",
      "-1492.0246221143802\n",
      "-1501.0207054608738\n",
      "-1510.7156636999125\n",
      "-1521.0161127345768\n",
      "-1530.637525817488\n",
      "-1539.594580386515\n",
      "-1547.927140220032\n",
      "-1555.6998025082996\n",
      "-1562.9998822904738\n",
      "-1569.9340567847667\n",
      "-1576.6241105112067\n",
      "-1583.2022299496102\n",
      "-6.589101584867894\n",
      "-12.979478556133497\n",
      "-19.31641748880696\n",
      "-25.748726491247375\n",
      "-32.42352341800846\n",
      "-39.48072546969368\n",
      "-47.04712877243932\n",
      "-55.230257664791765\n",
      "-64.11254200603902\n",
      "-73.74666792472281\n",
      "-84.15295840105482\n",
      "-93.87834041529257\n",
      "-102.88450070124752\n",
      "-111.21031400191819\n",
      "-118.92161861504127\n",
      "-126.10920760653067\n",
      "-132.8852495572145\n",
      "-139.37869032332034\n",
      "-145.7302110407434\n",
      "-152.0871066313173\n",
      "-158.598150976275\n",
      "-165.40829126923452\n",
      "-172.65297592940516\n",
      "-180.45210066201867\n",
      "-188.90390072050155\n",
      "-198.07948354510324\n",
      "-208.0188926781202\n",
      "-218.1859565364391\n",
      "-227.6235324485241\n",
      "-236.35400885932685\n",
      "-244.42706603589787\n",
      "-251.91876540511004\n",
      "-258.9288663592831\n",
      "-265.5767696302687\n",
      "-271.9966822677223\n",
      "-278.33251708416947\n",
      "-284.73277359052963\n",
      "-291.34536134598693\n",
      "-298.31216722127795\n",
      "-305.7632172789988\n",
      "-313.8105404584745\n",
      "-322.54221465255\n",
      "-332.01739830568675\n",
      "-342.2632308762565\n",
      "-352.1403689933505\n",
      "-361.2936420859712\n",
      "-369.7562406326015\n",
      "-377.5885076992393\n",
      "-384.87630203291985\n",
      "-391.72770578318034\n",
      "-398.2685871764238\n",
      "-404.63761131322553\n",
      "-410.9811200075716\n",
      "-417.44800752425635\n",
      "-424.18446853633714\n",
      "-431.3284124569361\n",
      "-439.00347469854415\n",
      "-447.312873911269\n",
      "-456.3337406852274\n",
      "-466.11279091399854\n",
      "-476.4317244734665\n",
      "-486.0198929948982\n",
      "-494.89406918258794\n",
      "-503.09827740488055\n",
      "-510.70326468598034\n",
      "-517.8041644153008\n",
      "-524.5166782503493\n",
      "-530.972354171268\n",
      "-537.3135105306413\n",
      "-543.688115646341\n",
      "-550.2446369666575\n",
      "-557.1266788001877\n",
      "-564.4672306815783\n",
      "-572.3825663521616\n",
      "-580.966194130325\n",
      "-590.2836087865611\n",
      "-600.3687392372556\n",
      "-610.3978956406943\n",
      "-619.6997129861844\n",
      "-628.3017063787279\n",
      "-636.2586524006499\n",
      "-643.6513315240113\n",
      "-650.5835458241613\n",
      "-657.1778691013756\n",
      "-663.5707290658853\n",
      "-669.9072938126338\n",
      "-676.3363521710777\n",
      "-683.0051055928699\n",
      "-690.053665237459\n",
      "-697.6091389453445\n",
      "-705.7794808878285\n",
      "-714.6476551137238\n",
      "-724.2669549733206\n",
      "-734.6583380018568\n",
      "-744.3978186424579\n",
      "-753.4175960824357\n",
      "-761.7560163819779\n",
      "-769.4784101309535\n",
      "-776.6751178309297\n",
      "-783.4579363120133\n",
      "-789.9555343612773\n",
      "-796.308414920934\n",
      "-802.6637935690717\n",
      "-809.1704649701575\n",
      "-815.9735026136397\n",
      "-823.2085948585102\n",
      "-830.9959965207225\n",
      "-839.434416634567\n",
      "-848.595530457975\n",
      "-858.5200055775987\n",
      "-868.7012073061451\n",
      "-878.1527541867972\n",
      "-886.8965104722706\n",
      "-894.9816317246525\n",
      "-902.4836897535318\n",
      "-909.502020975317\n",
      "-916.1556908550948\n",
      "-922.5786684125043\n",
      "-928.914727459506\n",
      "-935.3123274669571\n",
      "-941.9194396997941\n",
      "-948.8781213610312\n",
      "-956.3186853881705\n",
      "-964.3535665944381\n",
      "-973.0713573786637\n",
      "-982.5318116291643\n",
      "-992.7627018531679\n",
      "-1002.6539729975443\n",
      "-1011.8210067952093\n",
      "-1020.296465192184\n",
      "-1028.1401762215685\n",
      "-1035.4375321303562\n",
      "-1042.2962249972177\n",
      "-1048.8418257144874\n",
      "-1055.2128006035678\n",
      "-1061.5553916048052\n",
      "-1068.0184926688098\n",
      "-1074.7484022115939\n",
      "-1081.883245332552\n",
      "-1089.546991726468\n",
      "-1097.8433111086515\n",
      "-1106.8498849372243\n",
      "-1116.614045276275\n",
      "-1126.9470880586832\n",
      "-1136.5493047143805\n",
      "-1145.4369480208816\n",
      "-1153.6535148491334\n",
      "-1161.2692524610097\n",
      "-1168.3788552918606\n",
      "-1175.0976703775805\n",
      "-1181.556987149657\n",
      "-1187.8989644193234\n",
      "-1194.2715098187623\n",
      "-1200.8231309184976\n",
      "-1207.6975790979695\n",
      "-1215.0281060604134\n",
      "-1222.9313670320566\n",
      "-1231.5013639533254\n",
      "-1240.804173359678\n",
      "-1250.874353491103\n",
      "-1260.917655300272\n",
      "-1270.233353975085\n",
      "-1278.8484377203124\n",
      "-1286.8171623036587\n",
      "-1294.2198289811954\n",
      "-1301.1598321362978\n",
      "-1307.7594282024586\n",
      "-1314.1548255190985\n",
      "-1320.4910717928403\n",
      "-1326.9169346370986\n",
      "-1333.5796970505164\n",
      "-1340.619661938748\n",
      "-1348.16424654286\n",
      "-1356.321832660418\n",
      "-1365.1759167538544\n",
      "-1374.7803983828312\n",
      "-1385.1568695912454\n",
      "-1394.9104529952867\n",
      "-1403.9438619100083\n",
      "-1412.2949136628554\n",
      "-1420.0284303903052\n",
      "-1427.2342986844915\n",
      "-1434.0239418941603\n",
      "-1440.525749844432\n",
      "-1446.8800453697663\n",
      "-1453.2339627934668\n",
      "-1459.7363155914154\n",
      "-1466.5323014355822\n",
      "-1473.7578463566786\n",
      "-1481.5335619772043\n",
      "-1489.9586290341838\n",
      "-1499.10528909413\n",
      "-1509.0148331456664\n",
      "-1519.2101709739768\n",
      "-1528.675696957217\n",
      "-1537.4327514972422\n",
      "-1545.5299651252674\n",
      "-1553.042419030339\n",
      "-1560.0690251264934\n",
      "-1.0215894286503815\n",
      "-2.135562309332813\n",
      "-3.4971988464372608\n",
      "-5.284734607606735\n",
      "-7.711758558909814\n",
      "-11.035966874509732\n",
      "-15.559882555785249\n",
      "-21.61739359514627\n",
      "-29.5406392614727\n",
      "-39.60811284163323\n",
      "-51.987786182158885\n",
      "-66.1904556025896\n",
      "-78.37486192215405\n",
      "-88.51144277191278\n",
      "-96.67544281373436\n",
      "-103.04995114442971\n",
      "-107.89487187666563\n",
      "-111.50180040341623\n",
      "-114.1552423012076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-116.10974087414543\n",
      "-117.58251742360457\n",
      "-118.75691248582625\n",
      "-119.79186178736516\n",
      "-120.83419984530966\n",
      "-122.03210515472776\n",
      "-123.54886033615277\n",
      "-125.57615199178414\n",
      "-128.345338306935\n",
      "-132.13349125709638\n",
      "-137.25896850553937\n",
      "-144.06017445602365\n",
      "-152.8538413795145\n",
      "-163.8784909162806\n",
      "-177.24291914765442\n",
      "-190.60829322596553\n",
      "-201.93206610890383\n",
      "-211.2257179814268\n",
      "-218.611618848901\n",
      "-224.31020701911518\n",
      "-228.60016983322416\n",
      "-231.7740183211896\n",
      "-234.1055011939611\n",
      "-235.8336636758341\n",
      "-237.16065911076137\n",
      "-238.2582237103688\n",
      "-239.27862977517114\n",
      "-240.3676060352048\n",
      "-241.6779937005969\n",
      "-243.38343418990985\n",
      "-245.69108417582316\n",
      "-248.8511979698837\n",
      "-253.1595268539837\n",
      "-258.9465839424502\n",
      "-266.5478958477077\n",
      "-276.2545977848913\n",
      "-288.255811545751\n",
      "-302.5976163625962\n",
      "-315.1119512589616\n",
      "-325.5767835913452\n",
      "-334.04920081965764\n",
      "-340.6962863457686\n",
      "-345.76852364616934\n",
      "-349.55536528647184\n",
      "-352.34445820947207\n",
      "-354.3960353141582\n",
      "-355.9333249983212\n",
      "-357.1446025953294\n",
      "-358.1919556148983\n",
      "-359.2232785932584\n",
      "-360.38560307963166\n",
      "-361.8388507378641\n",
      "-363.76928251001755\n",
      "-366.4012587496517\n",
      "-370.0044263163296\n",
      "-374.89140716931115\n",
      "-381.3996588722761\n",
      "-389.8530093560753\n",
      "-400.50654370844234\n",
      "-413.49242415384236\n",
      "-427.181776982336\n",
      "-438.83685680455426\n",
      "-448.4526697754818\n",
      "-456.1335882683686\n",
      "-462.08647840863654\n",
      "-466.58377408951486\n",
      "-469.91838535374865\n",
      "-472.36859178707147\n",
      "-474.1794843766453\n",
      "-475.5588977078237\n",
      "-476.6828124582588\n",
      "-477.7057985130117\n",
      "-478.7737264481844\n",
      "-480.0373565593235\n",
      "-481.66607133699836\n",
      "-483.86085301914216\n",
      "-486.86458954063477\n",
      "-490.96599499090416\n",
      "-496.49143706842096\n",
      "-503.7785207969007\n",
      "-513.129467618589\n",
      "-524.7534209223335\n",
      "-538.7207841399947\n",
      "-551.5638166630208\n",
      "-562.3583655126457\n",
      "-571.1436103081496\n",
      "-578.0698919708284\n",
      "-583.3770676737921\n",
      "-587.351362005319\n",
      "-590.2828969131011\n",
      "-592.4373559219301\n",
      "-594.0440388205272\n",
      "-595.2963911872832\n",
      "-596.3599682702472\n",
      "-597.3840732158587\n",
      "-598.5149498303599\n",
      "-599.9095114940528\n",
      "-601.7489054291251\n",
      "-604.2506916988065\n",
      "-607.6770461170078\n",
      "-612.3343943011108\n",
      "-618.5582402949167\n",
      "-626.6780356058908\n",
      "-636.9639548922167\n",
      "-649.5708090181967\n",
      "-663.5818374957335\n",
      "-675.5680244930827\n",
      "-685.5087318745295\n",
      "-693.4901364843452\n",
      "-699.7045188954888\n",
      "-704.4168457309014\n",
      "-707.9194998860837\n",
      "-710.4948150130467\n",
      "-712.3938335872903\n",
      "-713.8302216174394\n",
      "-714.9844817502043\n",
      "-716.0138149729969\n",
      "-717.0645886613961\n",
      "-718.28584121871\n",
      "-719.8430377382452\n",
      "-721.9312619547018\n",
      "-724.7861498612996\n",
      "-728.6891799649512\n",
      "-733.9618934607895\n",
      "-740.9427426265536\n",
      "-749.9434820448282\n",
      "-761.1920249282153\n",
      "-774.7828933377357\n",
      "-787.9530496846658\n",
      "-799.0782995482396\n",
      "-808.1803354083968\n",
      "-815.3921532214658\n",
      "-820.941809372355\n",
      "-825.1111665440616\n",
      "-828.1920813197016\n",
      "-830.4553867668258\n",
      "-832.1364791136102\n",
      "-833.4341894153707\n",
      "-834.5178478237731\n",
      "-835.5385113418505\n",
      "-836.6419945526867\n",
      "-837.9825578743935\n",
      "-839.736557011262\n",
      "-842.1149749362189\n",
      "-845.3725207645972\n",
      "-849.8090416013392\n",
      "-855.7571720081258\n",
      "-863.5505698075835\n",
      "-873.4729779015192\n",
      "-885.7009659612528\n",
      "-900.0311516995521\n",
      "-912.3478276224326\n",
      "-922.6156748910814\n",
      "-930.902646894626\n",
      "-937.3855184753719\n",
      "-942.3205665892722\n",
      "-945.9986551861507\n",
      "-948.7056233003558\n",
      "-950.6983179254339\n",
      "-952.1963562814149\n",
      "-953.3850259613729\n",
      "-954.4244866223978\n",
      "-955.4619553066613\n",
      "-956.6451079765316\n",
      "-958.1358389643958\n",
      "-960.1236250354337\n",
      "-962.836999622878\n",
      "-966.550069670188\n",
      "-971.5789560262258\n",
      "-978.2618104682975\n",
      "-986.9183870183602\n",
      "-997.7940144552553\n",
      "-1011.006922063037\n",
      "-1024.5023193779305\n",
      "-1035.9587856417247\n",
      "-1045.3811123643382\n",
      "-1052.8844954271856\n",
      "-1058.6840640274295\n",
      "-1063.0561454479378\n",
      "-1066.2935173418355\n",
      "-0.03580562393545927\n",
      "-0.08307656564940463\n",
      "-0.15003728743794437\n",
      "-0.24784194716489807\n",
      "-0.3922094283390304\n",
      "-0.6056929929839695\n",
      "-0.920865365397842\n",
      "-1.3847698109262592\n",
      "-2.0650373915221474\n",
      "-3.0580361011339723\n",
      "-4.499165601232887\n",
      "-6.57470028454276\n",
      "-9.533059533382168\n",
      "-13.6907398400574\n",
      "-19.42470009273491\n",
      "-27.140909408651357\n",
      "-37.21309644560449\n",
      "-49.9019579104947\n",
      "-65.28917705742067\n",
      "-79.15385443926046\n",
      "-90.6897714391904\n",
      "-99.9434809199323\n",
      "-107.10589404323909\n",
      "-112.47619643302029\n",
      "-116.3983796186926\n",
      "-119.20457030824498\n",
      "-121.18130602683152\n",
      "-122.55778131174775\n",
      "-123.50811814850832\n",
      "-124.16003022493346\n",
      "-124.60498222845389\n",
      "-124.90744116458376\n",
      "-125.11238637629245\n",
      "-125.25103344753855\n",
      "-125.3450402815436\n",
      "-125.40953774242752\n",
      "-125.45530141543873\n",
      "-125.49032522693186\n",
      "-125.52100267017046\n",
      "-125.55307870414985\n",
      "-125.5925082000418\n",
      "-125.64634540350474\n",
      "-125.72379315946311\n",
      "-125.83756100993097\n",
      "-126.00571854439269\n",
      "-126.25428463156422\n",
      "-126.62086067848315\n",
      "-127.15968263392884\n",
      "-127.94849387271275\n",
      "-129.09754284582522\n",
      "-130.7606141456322\n",
      "-133.14701982949094\n",
      "-136.53153856399345\n",
      "-141.2562278827707\n",
      "-147.71471475868574\n",
      "-156.3092395832817\n",
      "-167.3792628073906\n",
      "-181.12118628601615\n",
      "-196.37427794909178\n",
      "-209.3347171579755\n",
      "-219.96730594635966\n",
      "-228.375866504288\n",
      "-234.8001871555469\n",
      "-239.564703433652\n",
      "-243.01439095679152\n",
      "-245.46626343802518\n",
      "-247.1849368131573\n",
      "-248.37737269357714\n",
      "-249.19841171877698\n",
      "-249.76044687489545\n",
      "-250.14340739121965\n",
      "-250.4033729516285\n",
      "-250.57936799931443\n",
      "-250.69845456375876\n",
      "-250.7794396152333\n",
      "-250.8355361219257\n",
      "-250.87627386778067\n",
      "-250.9088983251667\n",
      "-250.93944494419068\n",
      "-250.97363943977595\n",
      "-251.01775363885068\n",
      "-251.07954115054835\n",
      "-251.16938758880352\n",
      "-251.30183693374136\n",
      "-251.497699610527\n",
      "-251.78700810248128\n",
      "-252.21315568095892\n",
      "-252.83861167210333\n",
      "-253.75259916064832\n",
      "-255.08093341299912\n",
      "-256.99763664909943\n",
      "-259.7366331932973\n",
      "-263.59944059929694\n",
      "-268.95140717341985\n",
      "-276.19633369312567\n",
      "-285.7216805470966\n",
      "-297.8199577573597\n",
      "-312.6155541611933\n",
      "-326.98625980284265\n",
      "-339.03647460132487\n",
      "-348.7815619681413\n",
      "-356.38201859872197\n",
      "-362.1182748717167\n",
      "-366.3299545384436\n",
      "-369.35557008007436\n",
      "-371.4933767178796\n",
      "-372.9853669770644\n",
      "-374.0171826252247\n",
      "-374.7258927050601\n",
      "-375.2101032515353\n",
      "-375.5395208993357\n",
      "-375.762868650726\n",
      "-375.9139862932262\n",
      "-376.0163419148265\n",
      "-376.0862927087274\n",
      "-376.13542155032343\n",
      "-376.17222299034256\n",
      "-376.20335569101235\n",
      "-376.2346324887003\n",
      "-376.2718885878854\n",
      "-376.32185352258534\n",
      "-376.3931533310621\n",
      "-376.4975861436096\n",
      "-376.6518478637865\n",
      "-376.8799352459124\n",
      "-377.21651896831884\n",
      "-377.71164823472384\n",
      "-378.4371897362686\n",
      "-379.4953443607432\n",
      "-381.0292757193266\n",
      "-383.23506295031405\n",
      "-386.3724915344801\n",
      "-390.76936168045535\n",
      "-396.81055629808054\n",
      "-404.90168289331496\n",
      "-415.403154858996\n",
      "-428.54888013540796\n",
      "-444.2925193257866\n",
      "-457.7653737087587\n",
      "-468.90730713882635\n",
      "-477.7895925469086\n",
      "-484.62526548373273\n",
      "-489.7257395171384\n",
      "-493.436440145391\n",
      "-496.083463771327\n",
      "-497.9439647045503\n",
      "-499.23738913087766\n",
      "-500.12929996590026\n",
      "-500.7405603164021\n",
      "-501.1574530959957\n",
      "-501.4406662228888\n",
      "-501.6324901830479\n",
      "-501.76226185052093\n",
      "-501.8503472996819\n",
      "-501.91100605171175\n",
      "-501.95444476310337\n",
      "-501.98831124308145\n",
      "-502.01882629738486\n",
      "-502.0517107435387\n",
      "-502.09304043458894\n",
      "-502.1501533779702\n",
      "-502.23273999420627\n",
      "-502.35427072916184\n",
      "-502.5339554257676\n",
      "-502.79948579607833\n",
      "-503.1908811318616\n",
      "-503.76582096730203\n",
      "-504.6068624344577\n",
      "-505.8308064784584\n",
      "-507.6000062836439\n",
      "-510.134293430559\n",
      "-513.7200652636558\n",
      "-518.7098629630958\n",
      "-525.5026431477008\n",
      "-534.4956643645671\n",
      "-546.0095042955988\n",
      "-560.210007777756\n",
      "-575.0817637141962\n",
      "-587.6468818298929\n",
      "-597.8912545043013\n",
      "-605.9436295123601\n",
      "-612.0625775100742\n",
      "-616.5803455442644\n",
      "-619.8399290910083\n",
      "-622.1505559564092\n",
      "-623.7670448480952\n",
      "-624.8869562788714\n",
      "-625.6572162213547\n",
      "-626.1840403526493\n",
      "-626.5427597736164\n",
      "-626.7861364294168\n",
      "-626.9508520712005\n",
      "-627.0623420704349\n",
      "-627.1383023801391\n",
      "-627.1912042229603\n",
      "-627.2301029520535\n",
      "-627.2619699517478\n",
      "-627.2927276270125\n",
      "-627.3281333868521\n",
      "-0.16070431323996348\n",
      "-0.3624075410282264\n",
      "-0.6396534088201451\n",
      "-1.0375669184152472\n",
      "-1.6178068631769433\n",
      "-2.4661680207905254\n",
      "-3.7021124965748617\n",
      "-5.489996337622731\n",
      "-8.050607267451337\n",
      "-11.669505796162518\n",
      "-16.695563105905798\n",
      "-23.520264487706804\n",
      "-32.52951882186444\n",
      "-44.03049960507109\n",
      "-58.17745031379948\n",
      "-72.81014971453376\n",
      "-85.16645050198568\n",
      "-95.23820791768543\n",
      "-103.15618599421012\n",
      "-109.17580602529117\n",
      "-113.62266111074132\n",
      "-116.83216710471628\n",
      "-119.10694441953486\n",
      "-120.6970046698641\n",
      "-121.79698619024876\n",
      "-122.55255377374316\n",
      "-123.07008322283433\n",
      "-123.42637659584486\n",
      "-123.67705889995942\n",
      "-123.86337711200693\n",
      "-124.01761932377379\n",
      "-124.16755839691967\n",
      "-124.34037417154839\n",
      "-124.56651524732743\n",
      "-124.88396811925297\n",
      "-125.34341685498133\n",
      "-126.0147794838667\n",
      "-126.99553525196288\n",
      "-128.42097898187023\n",
      "-130.4758221357349\n",
      "-133.40507089308394\n",
      "-137.51957267473958\n",
      "-143.18837015188438\n",
      "-150.80811220388694\n",
      "-160.7439909399342\n",
      "-173.25204588778692\n",
      "-188.41533944603668\n",
      "-202.18327208099555\n",
      "-213.65678697308448\n",
      "-222.87904308405558\n",
      "-230.03322248831444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-3c969f8f4326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     return self._model_iteration(\n\u001b[0;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(trainingX, trainingY, epochs=2)\n",
    "scores = []\n",
    "num_trials = 10\n",
    "sim_steps = 200\n",
    "for _ in range(num_trials):\n",
    "    observation = env.reset()\n",
    "    score = 0\n",
    "    for _ in range(sim_steps):\n",
    "        action = np.argmax(model.predict(observation.reshape(1,3)))\n",
    "        observation, reward, done, _ = env.step([action,1])\n",
    "        score += reward\n",
    "        if done:            \n",
    "            break\n",
    "        print(score)\n",
    "    scores.append(score)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
