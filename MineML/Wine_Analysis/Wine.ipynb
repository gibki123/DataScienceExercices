{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_wine.csv\")\n",
    "mapping = {'poor': 0,'medium': 1, 'good': 2,  'excellent': 3}\n",
    "df['class'] = [mapping[item] for item in df['class']] \n",
    "\n",
    "dummies = pd.get_dummies(df['color'], drop_first = True)\n",
    "df = df.drop(['color'], axis=1)\n",
    "df['isWhite'] = dummies\n",
    "\n",
    "dummies_vineyard = pd.get_dummies(df['vineyard'], drop_first = True)\n",
    "df = df.drop(['vineyard'], axis=1)\n",
    "df = pd.concat([df, dummies_vineyard], axis=1)\n",
    "\n",
    "dummies_chlor = pd.get_dummies(df['chlor.class'], drop_first = True)\n",
    "df = df.drop(['chlor.class'], axis=1)\n",
    "df = pd.concat([df, dummies_chlor], axis=1)\n",
    "\n",
    "dummies_condition = pd.get_dummies(df['condition'], drop_first = True)\n",
    "df = df.drop(['condition'], axis=1)\n",
    "df = pd.concat([df, dummies_condition], axis=1)\n",
    "\n",
    "df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class']\n",
    "x = df.drop(['class'], axis= 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        55\n",
      "           1       0.47      0.36      0.41       449\n",
      "           2       0.68      0.82      0.74       893\n",
      "           3       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.29      0.30      0.29      1438\n",
      "weighted avg       0.57      0.63      0.59      1438\n",
      "\n",
      "[[  0  24  31   0]\n",
      " [  0 163 286   0]\n",
      " [  0 157 736   0]\n",
      " [  0   5  36   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1  21  33   0]\n",
      " [  0 171 278   0]\n",
      " [  0 109 784   0]\n",
      " [  0   1  39   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04        55\n",
      "           1       0.57      0.38      0.46       449\n",
      "           2       0.69      0.88      0.77       893\n",
      "           3       1.00      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.67      1438\n",
      "   macro avg       0.81      0.33      0.33      1438\n",
      "weighted avg       0.67      0.67      0.63      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train,y_train)\n",
    "predictions = svc_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.15      0.15        55\n",
      "           1       0.54      0.59      0.56       449\n",
      "           2       0.75      0.72      0.73       893\n",
      "           3       0.16      0.15      0.15        41\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.40      0.40      0.40      1438\n",
      "weighted avg       0.64      0.64      0.64      1438\n",
      "\n",
      "[[  8  25  20   2]\n",
      " [ 21 264 161   3]\n",
      " [ 26 197 643  27]\n",
      " [  0   2  33   6]]\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "predictions = dtree.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        55\n",
      "           1       0.66      0.59      0.62       449\n",
      "           2       0.76      0.88      0.81       893\n",
      "           3       0.50      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.73      1438\n",
      "   macro avg       0.48      0.37      0.37      1438\n",
      "weighted avg       0.69      0.73      0.70      1438\n",
      "\n",
      "[[  0  30  25   0]\n",
      " [  0 266 183   0]\n",
      " [  0 110 782   1]\n",
      " [  0   0  40   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train,y_train)\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "df3 = pd.read_csv(\"test_wine.csv\")\n",
    "df3 = df3.drop(['id'], axis=1)\n",
    "df2 = pd.concat([df2, df3], axis=1)\n",
    "df2 = df2.drop(['id'], axis=1)\n",
    "mapping = {'poor': 0,'medium': 1, 'good': 2,  'excellent': 3}\n",
    "df2['class'] = [mapping[item] for item in df2['class']] \n",
    "\n",
    "dummies = pd.get_dummies(df2['color'], drop_first = True)\n",
    "df2 = df2.drop(['color'], axis=1)\n",
    "df2['isWhite'] = dummies\n",
    "\n",
    "dummies_vineyard = pd.get_dummies(df2['vineyard'], drop_first = True)\n",
    "df2 = df2.drop(['vineyard'], axis=1)\n",
    "df2 = pd.concat([df2, dummies_vineyard], axis=1)\n",
    "\n",
    "dummies_chlor = pd.get_dummies(df2['chlor.class'], drop_first = True)\n",
    "df2 = df2.drop(['chlor.class'], axis=1)\n",
    "df2 = pd.concat([df2, dummies_chlor], axis=1)\n",
    "\n",
    "dummies_condition = pd.get_dummies(df2['condition'], drop_first = True)\n",
    "df2 = df2.drop(['condition'], axis=1)\n",
    "df2 = pd.concat([df2, dummies_condition], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df3['class']\n",
    "x = df3.drop(['class'], axis= 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        55\n",
      "           1       0.46      0.30      0.36       680\n",
      "           2       0.68      0.84      0.75      1371\n",
      "           3       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.63      2145\n",
      "   macro avg       0.28      0.29      0.28      2145\n",
      "weighted avg       0.58      0.63      0.60      2145\n",
      "\n",
      "[[   0   19   36    0]\n",
      " [   0  205  475    0]\n",
      " [   0  219 1152    0]\n",
      " [   0    1   38    0]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   20   35    0]\n",
      " [   0  243  437    0]\n",
      " [   0  180 1191    0]\n",
      " [   0    2   37    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        55\n",
      "           1       0.55      0.36      0.43       680\n",
      "           2       0.70      0.87      0.78      1371\n",
      "           3       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.67      2145\n",
      "   macro avg       0.31      0.31      0.30      2145\n",
      "weighted avg       0.62      0.67      0.63      2145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train,y_train)\n",
    "predictions = svc_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.07      0.08        55\n",
      "           1       0.61      0.63      0.62       680\n",
      "           2       0.79      0.78      0.78      1371\n",
      "           3       0.09      0.10      0.10        39\n",
      "\n",
      "    accuracy                           0.70      2145\n",
      "   macro avg       0.39      0.40      0.39      2145\n",
      "weighted avg       0.70      0.70      0.70      2145\n",
      "\n",
      "[[   4   24   27    0]\n",
      " [  19  429  228    4]\n",
      " [  21  249 1066   35]\n",
      " [   2    1   32    4]]\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "predictions = dtree.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        55\n",
      "           1       0.75      0.65      0.69       680\n",
      "           2       0.80      0.91      0.85      1371\n",
      "           3       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.79      2145\n",
      "   macro avg       0.39      0.39      0.39      2145\n",
      "weighted avg       0.75      0.79      0.77      2145\n",
      "\n",
      "[[   0   27   28    0]\n",
      " [   0  442  238    0]\n",
      " [   0  123 1247    1]\n",
      " [   0    1   38    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train,y_train)\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, activation='relu', input_dim = 50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes=4)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4352 samples, validate on 2145 samples\n",
      "Epoch 1/200\n",
      "4352/4352 [==============================] - 0s 98us/sample - loss: 8.7407 - accuracy: 0.4095 - val_loss: 0.8620 - val_accuracy: 0.6392\n",
      "Epoch 2/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 2.4761 - accuracy: 0.4582 - val_loss: 0.8902 - val_accuracy: 0.6392\n",
      "Epoch 3/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 1.7445 - accuracy: 0.4736 - val_loss: 0.9012 - val_accuracy: 0.6392\n",
      "Epoch 4/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 1.3927 - accuracy: 0.5223 - val_loss: 0.8994 - val_accuracy: 0.6392\n",
      "Epoch 5/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 1.2404 - accuracy: 0.5250 - val_loss: 0.8804 - val_accuracy: 0.6392\n",
      "Epoch 6/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 1.1306 - accuracy: 0.5480 - val_loss: 0.8878 - val_accuracy: 0.6392\n",
      "Epoch 7/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 1.0879 - accuracy: 0.5620 - val_loss: 0.8753 - val_accuracy: 0.6392\n",
      "Epoch 8/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 1.0230 - accuracy: 0.5864 - val_loss: 0.8642 - val_accuracy: 0.6392\n",
      "Epoch 9/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.9984 - accuracy: 0.6048 - val_loss: 0.8657 - val_accuracy: 0.6392\n",
      "Epoch 10/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.9758 - accuracy: 0.6089 - val_loss: 0.8551 - val_accuracy: 0.6392\n",
      "Epoch 11/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.9477 - accuracy: 0.6147 - val_loss: 0.8607 - val_accuracy: 0.6392\n",
      "Epoch 12/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.9428 - accuracy: 0.6229 - val_loss: 0.8641 - val_accuracy: 0.6392\n",
      "Epoch 13/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.9377 - accuracy: 0.6268 - val_loss: 0.8606 - val_accuracy: 0.6392\n",
      "Epoch 14/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.9314 - accuracy: 0.6271 - val_loss: 0.8546 - val_accuracy: 0.6392\n",
      "Epoch 15/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.9050 - accuracy: 0.6330 - val_loss: 0.8435 - val_accuracy: 0.6392\n",
      "Epoch 16/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.9255 - accuracy: 0.6305 - val_loss: 0.8499 - val_accuracy: 0.6392\n",
      "Epoch 17/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8969 - accuracy: 0.6326 - val_loss: 0.8562 - val_accuracy: 0.6392\n",
      "Epoch 18/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8959 - accuracy: 0.6347 - val_loss: 0.8599 - val_accuracy: 0.6392\n",
      "Epoch 19/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8946 - accuracy: 0.6360 - val_loss: 0.8574 - val_accuracy: 0.6392\n",
      "Epoch 20/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8858 - accuracy: 0.6395 - val_loss: 0.8523 - val_accuracy: 0.6392\n",
      "Epoch 21/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8879 - accuracy: 0.6376 - val_loss: 0.8566 - val_accuracy: 0.6392\n",
      "Epoch 22/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8708 - accuracy: 0.6356 - val_loss: 0.8429 - val_accuracy: 0.6392\n",
      "Epoch 23/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8825 - accuracy: 0.6379 - val_loss: 0.8496 - val_accuracy: 0.6392\n",
      "Epoch 24/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8893 - accuracy: 0.6372 - val_loss: 0.8473 - val_accuracy: 0.6392\n",
      "Epoch 25/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8817 - accuracy: 0.6376 - val_loss: 0.8313 - val_accuracy: 0.6392\n",
      "Epoch 26/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8778 - accuracy: 0.6353 - val_loss: 0.8402 - val_accuracy: 0.6392\n",
      "Epoch 27/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8651 - accuracy: 0.6374 - val_loss: 0.8359 - val_accuracy: 0.6392\n",
      "Epoch 28/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8606 - accuracy: 0.6386 - val_loss: 0.8366 - val_accuracy: 0.6392\n",
      "Epoch 29/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8678 - accuracy: 0.6386 - val_loss: 0.8468 - val_accuracy: 0.6392\n",
      "Epoch 30/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8582 - accuracy: 0.6367 - val_loss: 0.8331 - val_accuracy: 0.6392\n",
      "Epoch 31/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8583 - accuracy: 0.6381 - val_loss: 0.8274 - val_accuracy: 0.6392\n",
      "Epoch 32/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8628 - accuracy: 0.6388 - val_loss: 0.8308 - val_accuracy: 0.6392\n",
      "Epoch 33/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8605 - accuracy: 0.6379 - val_loss: 0.8312 - val_accuracy: 0.6392\n",
      "Epoch 34/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8493 - accuracy: 0.6376 - val_loss: 0.8283 - val_accuracy: 0.6392\n",
      "Epoch 35/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8608 - accuracy: 0.6376 - val_loss: 0.8353 - val_accuracy: 0.6392\n",
      "Epoch 36/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8535 - accuracy: 0.6374 - val_loss: 0.8321 - val_accuracy: 0.6392\n",
      "Epoch 37/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8585 - accuracy: 0.6392 - val_loss: 0.8356 - val_accuracy: 0.6392\n",
      "Epoch 38/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8557 - accuracy: 0.6379 - val_loss: 0.8281 - val_accuracy: 0.6392\n",
      "Epoch 39/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8498 - accuracy: 0.6386 - val_loss: 0.8354 - val_accuracy: 0.6392\n",
      "Epoch 40/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8515 - accuracy: 0.6392 - val_loss: 0.8332 - val_accuracy: 0.6392\n",
      "Epoch 41/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8469 - accuracy: 0.6381 - val_loss: 0.8313 - val_accuracy: 0.6392\n",
      "Epoch 42/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8455 - accuracy: 0.6376 - val_loss: 0.8277 - val_accuracy: 0.6392\n",
      "Epoch 43/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.8487 - accuracy: 0.6379 - val_loss: 0.8314 - val_accuracy: 0.6392\n",
      "Epoch 44/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8427 - accuracy: 0.6381 - val_loss: 0.8280 - val_accuracy: 0.6392\n",
      "Epoch 45/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8452 - accuracy: 0.6365 - val_loss: 0.8250 - val_accuracy: 0.6392\n",
      "Epoch 46/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8446 - accuracy: 0.6386 - val_loss: 0.8280 - val_accuracy: 0.6392\n",
      "Epoch 47/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8457 - accuracy: 0.6392 - val_loss: 0.8271 - val_accuracy: 0.6392\n",
      "Epoch 48/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8387 - accuracy: 0.6390 - val_loss: 0.8252 - val_accuracy: 0.6392\n",
      "Epoch 49/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8447 - accuracy: 0.6386 - val_loss: 0.8248 - val_accuracy: 0.6392\n",
      "Epoch 50/200\n",
      "4352/4352 [==============================] - 0s 24us/sample - loss: 0.8401 - accuracy: 0.6383 - val_loss: 0.8220 - val_accuracy: 0.6392\n",
      "Epoch 51/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8403 - accuracy: 0.6379 - val_loss: 0.8225 - val_accuracy: 0.6392\n",
      "Epoch 52/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8406 - accuracy: 0.6376 - val_loss: 0.8263 - val_accuracy: 0.6392\n",
      "Epoch 53/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8402 - accuracy: 0.6388 - val_loss: 0.8256 - val_accuracy: 0.6392\n",
      "Epoch 54/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8336 - accuracy: 0.6386 - val_loss: 0.8186 - val_accuracy: 0.6392\n",
      "Epoch 55/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8344 - accuracy: 0.6381 - val_loss: 0.8229 - val_accuracy: 0.6392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8353 - accuracy: 0.6381 - val_loss: 0.8226 - val_accuracy: 0.6392\n",
      "Epoch 57/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8363 - accuracy: 0.6383 - val_loss: 0.8252 - val_accuracy: 0.6392\n",
      "Epoch 58/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8370 - accuracy: 0.6379 - val_loss: 0.8204 - val_accuracy: 0.6392\n",
      "Epoch 59/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8357 - accuracy: 0.6381 - val_loss: 0.8243 - val_accuracy: 0.6392\n",
      "Epoch 60/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8369 - accuracy: 0.6376 - val_loss: 0.8224 - val_accuracy: 0.6392\n",
      "Epoch 61/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8377 - accuracy: 0.6383 - val_loss: 0.8258 - val_accuracy: 0.6392\n",
      "Epoch 62/200\n",
      "4352/4352 [==============================] - 0s 24us/sample - loss: 0.8311 - accuracy: 0.6381 - val_loss: 0.8194 - val_accuracy: 0.6392\n",
      "Epoch 63/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8323 - accuracy: 0.6404 - val_loss: 0.8181 - val_accuracy: 0.6392\n",
      "Epoch 64/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8355 - accuracy: 0.6369 - val_loss: 0.8220 - val_accuracy: 0.6392\n",
      "Epoch 65/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8338 - accuracy: 0.6386 - val_loss: 0.8156 - val_accuracy: 0.6392\n",
      "Epoch 66/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8306 - accuracy: 0.6395 - val_loss: 0.8161 - val_accuracy: 0.6392\n",
      "Epoch 67/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8302 - accuracy: 0.6367 - val_loss: 0.8116 - val_accuracy: 0.6392\n",
      "Epoch 68/200\n",
      "4352/4352 [==============================] - 0s 24us/sample - loss: 0.8282 - accuracy: 0.6404 - val_loss: 0.8124 - val_accuracy: 0.6392\n",
      "Epoch 69/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8248 - accuracy: 0.6369 - val_loss: 0.8103 - val_accuracy: 0.6392\n",
      "Epoch 70/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8257 - accuracy: 0.6386 - val_loss: 0.8087 - val_accuracy: 0.6392\n",
      "Epoch 71/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8274 - accuracy: 0.6376 - val_loss: 0.8095 - val_accuracy: 0.6392\n",
      "Epoch 72/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8262 - accuracy: 0.6374 - val_loss: 0.8085 - val_accuracy: 0.6392\n",
      "Epoch 73/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8205 - accuracy: 0.6386 - val_loss: 0.8053 - val_accuracy: 0.6392\n",
      "Epoch 74/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8232 - accuracy: 0.6369 - val_loss: 0.8057 - val_accuracy: 0.6392\n",
      "Epoch 75/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8255 - accuracy: 0.6381 - val_loss: 0.8057 - val_accuracy: 0.6392\n",
      "Epoch 76/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8171 - accuracy: 0.6374 - val_loss: 0.8012 - val_accuracy: 0.6392\n",
      "Epoch 77/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8207 - accuracy: 0.6367 - val_loss: 0.8009 - val_accuracy: 0.6392\n",
      "Epoch 78/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8184 - accuracy: 0.6392 - val_loss: 0.7970 - val_accuracy: 0.6392\n",
      "Epoch 79/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8181 - accuracy: 0.6360 - val_loss: 0.7973 - val_accuracy: 0.6392\n",
      "Epoch 80/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8205 - accuracy: 0.6379 - val_loss: 0.7943 - val_accuracy: 0.6392\n",
      "Epoch 81/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8126 - accuracy: 0.6415 - val_loss: 0.7948 - val_accuracy: 0.6392\n",
      "Epoch 82/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.8121 - accuracy: 0.6397 - val_loss: 0.7891 - val_accuracy: 0.6392\n",
      "Epoch 83/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8141 - accuracy: 0.6406 - val_loss: 0.7912 - val_accuracy: 0.6392\n",
      "Epoch 84/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.8043 - accuracy: 0.6381 - val_loss: 0.7808 - val_accuracy: 0.6392\n",
      "Epoch 85/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8070 - accuracy: 0.6399 - val_loss: 0.7788 - val_accuracy: 0.6392\n",
      "Epoch 86/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.8078 - accuracy: 0.6397 - val_loss: 0.7772 - val_accuracy: 0.6396\n",
      "Epoch 87/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.8070 - accuracy: 0.6395 - val_loss: 0.7769 - val_accuracy: 0.6396\n",
      "Epoch 88/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.7926 - accuracy: 0.6432 - val_loss: 0.7751 - val_accuracy: 0.6448\n",
      "Epoch 89/200\n",
      "4352/4352 [==============================] - 0s 24us/sample - loss: 0.7974 - accuracy: 0.6507 - val_loss: 0.7662 - val_accuracy: 0.6452\n",
      "Epoch 90/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.7893 - accuracy: 0.6461 - val_loss: 0.7704 - val_accuracy: 0.6401\n",
      "Epoch 91/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.7932 - accuracy: 0.6429 - val_loss: 0.7628 - val_accuracy: 0.6490\n",
      "Epoch 92/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7850 - accuracy: 0.6514 - val_loss: 0.7503 - val_accuracy: 0.6508\n",
      "Epoch 93/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.7785 - accuracy: 0.6489 - val_loss: 0.7494 - val_accuracy: 0.6536\n",
      "Epoch 94/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7804 - accuracy: 0.6535 - val_loss: 0.7368 - val_accuracy: 0.6550\n",
      "Epoch 95/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7745 - accuracy: 0.6546 - val_loss: 0.7375 - val_accuracy: 0.6517\n",
      "Epoch 96/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.7736 - accuracy: 0.6530 - val_loss: 0.7567 - val_accuracy: 0.6648\n",
      "Epoch 97/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.7635 - accuracy: 0.6664 - val_loss: 0.7336 - val_accuracy: 0.6592\n",
      "Epoch 98/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7556 - accuracy: 0.6631 - val_loss: 0.7342 - val_accuracy: 0.6573\n",
      "Epoch 99/200\n",
      "4352/4352 [==============================] - 0s 24us/sample - loss: 0.7581 - accuracy: 0.6618 - val_loss: 0.7086 - val_accuracy: 0.6988\n",
      "Epoch 100/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7535 - accuracy: 0.6611 - val_loss: 0.7220 - val_accuracy: 0.6825\n",
      "Epoch 101/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.7531 - accuracy: 0.6668 - val_loss: 0.7144 - val_accuracy: 0.6932\n",
      "Epoch 102/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7502 - accuracy: 0.6762 - val_loss: 0.7288 - val_accuracy: 0.6713\n",
      "Epoch 103/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.7423 - accuracy: 0.6684 - val_loss: 0.7187 - val_accuracy: 0.6886\n",
      "Epoch 104/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7374 - accuracy: 0.6886 - val_loss: 0.6953 - val_accuracy: 0.7021\n",
      "Epoch 105/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.7389 - accuracy: 0.6815 - val_loss: 0.7102 - val_accuracy: 0.6909\n",
      "Epoch 106/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7366 - accuracy: 0.6824 - val_loss: 0.7082 - val_accuracy: 0.6979\n",
      "Epoch 107/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.7521 - accuracy: 0.6634 - val_loss: 0.6942 - val_accuracy: 0.7030\n",
      "Epoch 108/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7326 - accuracy: 0.6737 - val_loss: 0.7002 - val_accuracy: 0.6984\n",
      "Epoch 109/200\n",
      "4352/4352 [==============================] - 0s 22us/sample - loss: 0.7314 - accuracy: 0.6762 - val_loss: 0.6999 - val_accuracy: 0.6993\n",
      "Epoch 110/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7314 - accuracy: 0.6753 - val_loss: 0.7008 - val_accuracy: 0.6960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.7252 - accuracy: 0.6829 - val_loss: 0.6883 - val_accuracy: 0.7049\n",
      "Epoch 112/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7224 - accuracy: 0.6861 - val_loss: 0.6940 - val_accuracy: 0.6970\n",
      "Epoch 113/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7149 - accuracy: 0.6958 - val_loss: 0.6798 - val_accuracy: 0.7152\n",
      "Epoch 114/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7253 - accuracy: 0.6880 - val_loss: 0.7056 - val_accuracy: 0.6984\n",
      "Epoch 115/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7166 - accuracy: 0.6907 - val_loss: 0.6911 - val_accuracy: 0.7007\n",
      "Epoch 116/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7256 - accuracy: 0.6875 - val_loss: 0.6888 - val_accuracy: 0.7016\n",
      "Epoch 117/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7052 - accuracy: 0.6990 - val_loss: 0.6794 - val_accuracy: 0.7086\n",
      "Epoch 118/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7132 - accuracy: 0.6978 - val_loss: 0.6907 - val_accuracy: 0.7068\n",
      "Epoch 119/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7148 - accuracy: 0.6958 - val_loss: 0.6931 - val_accuracy: 0.7030\n",
      "Epoch 120/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7079 - accuracy: 0.6967 - val_loss: 0.6803 - val_accuracy: 0.7026\n",
      "Epoch 121/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7109 - accuracy: 0.6884 - val_loss: 0.6908 - val_accuracy: 0.6960\n",
      "Epoch 122/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7083 - accuracy: 0.7036 - val_loss: 0.6757 - val_accuracy: 0.7147\n",
      "Epoch 123/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7081 - accuracy: 0.6965 - val_loss: 0.6814 - val_accuracy: 0.6984\n",
      "Epoch 124/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7128 - accuracy: 0.6990 - val_loss: 0.6857 - val_accuracy: 0.7007\n",
      "Epoch 125/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7058 - accuracy: 0.7043 - val_loss: 0.6930 - val_accuracy: 0.6960\n",
      "Epoch 126/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7045 - accuracy: 0.6990 - val_loss: 0.6867 - val_accuracy: 0.7002\n",
      "Epoch 127/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7075 - accuracy: 0.6921 - val_loss: 0.6747 - val_accuracy: 0.7044\n",
      "Epoch 128/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7072 - accuracy: 0.7027 - val_loss: 0.6777 - val_accuracy: 0.7133\n",
      "Epoch 129/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7014 - accuracy: 0.7038 - val_loss: 0.6777 - val_accuracy: 0.7147\n",
      "Epoch 130/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7024 - accuracy: 0.6962 - val_loss: 0.6757 - val_accuracy: 0.7026\n",
      "Epoch 131/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6982 - accuracy: 0.7038 - val_loss: 0.6718 - val_accuracy: 0.7133\n",
      "Epoch 132/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.7033 - accuracy: 0.7047 - val_loss: 0.6695 - val_accuracy: 0.7170\n",
      "Epoch 133/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6937 - accuracy: 0.6981 - val_loss: 0.6726 - val_accuracy: 0.7161\n",
      "Epoch 134/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6969 - accuracy: 0.7022 - val_loss: 0.6670 - val_accuracy: 0.7040\n",
      "Epoch 135/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6937 - accuracy: 0.7075 - val_loss: 0.6626 - val_accuracy: 0.7128\n",
      "Epoch 136/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6889 - accuracy: 0.7075 - val_loss: 0.6720 - val_accuracy: 0.7082\n",
      "Epoch 137/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6949 - accuracy: 0.7029 - val_loss: 0.6812 - val_accuracy: 0.7100\n",
      "Epoch 138/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6898 - accuracy: 0.7114 - val_loss: 0.6716 - val_accuracy: 0.7161\n",
      "Epoch 139/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6910 - accuracy: 0.7031 - val_loss: 0.6697 - val_accuracy: 0.7086\n",
      "Epoch 140/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6825 - accuracy: 0.7146 - val_loss: 0.6668 - val_accuracy: 0.7114\n",
      "Epoch 141/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6842 - accuracy: 0.7139 - val_loss: 0.6646 - val_accuracy: 0.7138\n",
      "Epoch 142/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.7012 - accuracy: 0.7001 - val_loss: 0.6697 - val_accuracy: 0.7077\n",
      "Epoch 143/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6859 - accuracy: 0.7061 - val_loss: 0.6710 - val_accuracy: 0.7119\n",
      "Epoch 144/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.6879 - accuracy: 0.7080 - val_loss: 0.6613 - val_accuracy: 0.7189\n",
      "Epoch 145/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6928 - accuracy: 0.7024 - val_loss: 0.6630 - val_accuracy: 0.7114\n",
      "Epoch 146/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6852 - accuracy: 0.7105 - val_loss: 0.6762 - val_accuracy: 0.7035\n",
      "Epoch 147/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6862 - accuracy: 0.7057 - val_loss: 0.6627 - val_accuracy: 0.7124\n",
      "Epoch 148/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6752 - accuracy: 0.7146 - val_loss: 0.6585 - val_accuracy: 0.7175\n",
      "Epoch 149/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6872 - accuracy: 0.7086 - val_loss: 0.6683 - val_accuracy: 0.7091\n",
      "Epoch 150/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6785 - accuracy: 0.7096 - val_loss: 0.6626 - val_accuracy: 0.7072\n",
      "Epoch 151/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6796 - accuracy: 0.7089 - val_loss: 0.6585 - val_accuracy: 0.7152\n",
      "Epoch 152/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6724 - accuracy: 0.7197 - val_loss: 0.6695 - val_accuracy: 0.7128\n",
      "Epoch 153/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6776 - accuracy: 0.7112 - val_loss: 0.6642 - val_accuracy: 0.7100\n",
      "Epoch 154/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6776 - accuracy: 0.7070 - val_loss: 0.6621 - val_accuracy: 0.7156\n",
      "Epoch 155/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6815 - accuracy: 0.7116 - val_loss: 0.6629 - val_accuracy: 0.7170\n",
      "Epoch 156/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6792 - accuracy: 0.7137 - val_loss: 0.6772 - val_accuracy: 0.7100\n",
      "Epoch 157/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6778 - accuracy: 0.7054 - val_loss: 0.6641 - val_accuracy: 0.7082\n",
      "Epoch 158/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6758 - accuracy: 0.7135 - val_loss: 0.6605 - val_accuracy: 0.7133\n",
      "Epoch 159/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6775 - accuracy: 0.7109 - val_loss: 0.6776 - val_accuracy: 0.7170\n",
      "Epoch 160/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6784 - accuracy: 0.7167 - val_loss: 0.6723 - val_accuracy: 0.7072\n",
      "Epoch 161/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6750 - accuracy: 0.7194 - val_loss: 0.6702 - val_accuracy: 0.7086\n",
      "Epoch 162/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6801 - accuracy: 0.7080 - val_loss: 0.6659 - val_accuracy: 0.7124\n",
      "Epoch 163/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6852 - accuracy: 0.7068 - val_loss: 0.6595 - val_accuracy: 0.7184\n",
      "Epoch 164/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6780 - accuracy: 0.7132 - val_loss: 0.6610 - val_accuracy: 0.7114\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6789 - accuracy: 0.7089 - val_loss: 0.6595 - val_accuracy: 0.7207\n",
      "Epoch 166/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6753 - accuracy: 0.7128 - val_loss: 0.6694 - val_accuracy: 0.7058\n",
      "Epoch 167/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6737 - accuracy: 0.7165 - val_loss: 0.6609 - val_accuracy: 0.7133\n",
      "Epoch 168/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.6801 - accuracy: 0.7151 - val_loss: 0.6723 - val_accuracy: 0.7058\n",
      "Epoch 169/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6679 - accuracy: 0.7208 - val_loss: 0.6604 - val_accuracy: 0.7189\n",
      "Epoch 170/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.6679 - accuracy: 0.7125 - val_loss: 0.6654 - val_accuracy: 0.7198\n",
      "Epoch 171/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6714 - accuracy: 0.7109 - val_loss: 0.6659 - val_accuracy: 0.7026\n",
      "Epoch 172/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6699 - accuracy: 0.7240 - val_loss: 0.6633 - val_accuracy: 0.7124\n",
      "Epoch 173/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6680 - accuracy: 0.7114 - val_loss: 0.6540 - val_accuracy: 0.7226\n",
      "Epoch 174/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6722 - accuracy: 0.7125 - val_loss: 0.6653 - val_accuracy: 0.7077\n",
      "Epoch 175/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6741 - accuracy: 0.7197 - val_loss: 0.6553 - val_accuracy: 0.7240\n",
      "Epoch 176/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6700 - accuracy: 0.7165 - val_loss: 0.6603 - val_accuracy: 0.7207\n",
      "Epoch 177/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6762 - accuracy: 0.7107 - val_loss: 0.6638 - val_accuracy: 0.7054\n",
      "Epoch 178/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6642 - accuracy: 0.7227 - val_loss: 0.6574 - val_accuracy: 0.7240\n",
      "Epoch 179/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6641 - accuracy: 0.7222 - val_loss: 0.6659 - val_accuracy: 0.7086\n",
      "Epoch 180/200\n",
      "4352/4352 [==============================] - 0s 23us/sample - loss: 0.6741 - accuracy: 0.7100 - val_loss: 0.6639 - val_accuracy: 0.7100\n",
      "Epoch 181/200\n",
      "4352/4352 [==============================] - 0s 21us/sample - loss: 0.6653 - accuracy: 0.7151 - val_loss: 0.6726 - val_accuracy: 0.7044\n",
      "Epoch 182/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6628 - accuracy: 0.7135 - val_loss: 0.6651 - val_accuracy: 0.7072\n",
      "Epoch 183/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6641 - accuracy: 0.7130 - val_loss: 0.6613 - val_accuracy: 0.7170\n",
      "Epoch 184/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6645 - accuracy: 0.7169 - val_loss: 0.6595 - val_accuracy: 0.7175\n",
      "Epoch 185/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6586 - accuracy: 0.7266 - val_loss: 0.6605 - val_accuracy: 0.7170\n",
      "Epoch 186/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6575 - accuracy: 0.7247 - val_loss: 0.6619 - val_accuracy: 0.7096\n",
      "Epoch 187/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6724 - accuracy: 0.7197 - val_loss: 0.6745 - val_accuracy: 0.7156\n",
      "Epoch 188/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6657 - accuracy: 0.7213 - val_loss: 0.6580 - val_accuracy: 0.7231\n",
      "Epoch 189/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6556 - accuracy: 0.7188 - val_loss: 0.6699 - val_accuracy: 0.7179\n",
      "Epoch 190/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6638 - accuracy: 0.7176 - val_loss: 0.6713 - val_accuracy: 0.7184\n",
      "Epoch 191/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6632 - accuracy: 0.7215 - val_loss: 0.6563 - val_accuracy: 0.7207\n",
      "Epoch 192/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6589 - accuracy: 0.7174 - val_loss: 0.6757 - val_accuracy: 0.7105\n",
      "Epoch 193/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6692 - accuracy: 0.7194 - val_loss: 0.6729 - val_accuracy: 0.7044\n",
      "Epoch 194/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6625 - accuracy: 0.7204 - val_loss: 0.6597 - val_accuracy: 0.7249\n",
      "Epoch 195/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6607 - accuracy: 0.7188 - val_loss: 0.6791 - val_accuracy: 0.7054\n",
      "Epoch 196/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6631 - accuracy: 0.7213 - val_loss: 0.6618 - val_accuracy: 0.7156\n",
      "Epoch 197/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6519 - accuracy: 0.7284 - val_loss: 0.6640 - val_accuracy: 0.7193\n",
      "Epoch 198/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6609 - accuracy: 0.7233 - val_loss: 0.6643 - val_accuracy: 0.7119\n",
      "Epoch 199/200\n",
      "4352/4352 [==============================] - 0s 20us/sample - loss: 0.6678 - accuracy: 0.7183 - val_loss: 0.6646 - val_accuracy: 0.7221\n",
      "Epoch 200/200\n",
      "4352/4352 [==============================] - 0s 19us/sample - loss: 0.6546 - accuracy: 0.7199 - val_loss: 0.6655 - val_accuracy: 0.7142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f11c95688>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train.values, y=y_train, epochs=200, batch_size=128, validation_data=(X_test.values, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24f11c04108>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145/2145 [==============================] - 0s 22us/sample - loss: 0.6655 - accuracy: 0.7142\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6655338591906852, 0.7142191]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'fixed.acidity', 'acid.sulfur', 'volatile.acidity',\n",
       "       'sulfur.taste', 'citric.acid', 'residual.sugar', 'chlorides',\n",
       "       'free.sulfur.dioxide', 'total.sulfur.dioxide', 'density', 'pH',\n",
       "       'acid.taste', 'sulphates', 'acidity.variance', 'alcohol', 'isWhite',\n",
       "       'B', 'C', 'D', 'E', 'b2', 'b3', 'c1', 'c2', 'c3', 'd1', 'd2', 'd3',\n",
       "       'e1', 'e2', 'e3', 'f1', 'f2', 'f3', 'g1', 'g2', 'g3', 'h1', 'h2', 'h3',\n",
       "       'i1', 'i2', 'i3', 'I1', 'I2', 'P1', 'P2', 'S1', 'S2', 'S3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(['B', 'C', 'D', 'E', 'b2', 'b3', 'c1', 'c2', 'c3', 'd1', 'd2', 'd3',\n",
    "       'e1', 'e2', 'e3', 'f1', 'f2', 'f3', 'g1', 'g2', 'g3', 'h1', 'h2', 'h3',\n",
    "       'i1', 'i2', 'i3', 'I1', 'I2', 'P1', 'P2', 'S1', 'S2', 'S3'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
